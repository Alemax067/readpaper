# 借助大语言模型的查重算法研究现状
传统的查重算法主要依赖于文本的字面相似度，如词频、词向量等。然而，语言模型擅长语义理解，可以检测到表面上不同但语义相似的内容。这使得它们在处理复杂的文本改写、同义词替换等情况下具有更高的查重准确度。  

一些研究已经开始将语言模型应用于学术查重系统中。例如，使用 BERT 模型来捕捉学术论文中的语义相似度，帮助识别不同表达形式的相同学术观点。然而，想要在特定领域实现文本语义相似度的计算，如文本查重，依靠预训练的语义提取模型往往是不行的，需要大量高质量标注数据进行进一步的对比学习。这些数据如果依靠人力标注，将产生巨大的成本。因此，一些研究尝试利用大规模生成式语言模型来解决相似度标注、正/负样本生成等难题。

## 一、Improving Contrastive Learning of Sentence Embeddings from AI Feedback

### 1.1 任务概述
通过对比学习增强文本嵌入的性能，提高文本嵌入的质量。

困境：文本对缺乏细粒度标注（如文本相似度的标签可以细分至 0.8、0.9，而非全部都是 0 或 1），无法进行有效的监督学习，而无监督学习又存在缺陷

### 1.2 方法概述

#### 1.2.1 对比学习方法总结
![](../imgs/屏幕截图%202024-08-31%20141526.jpg)

1. 零反馈对比学习 (CLZF)  
通过数据增强 (如 dropout ) 策略构造正样本对，不同句子组合作为负样本对。损失函数常用 InfoNCE:  
$$
\mathcal{L}_{InfoNCE} = -\log\frac{\exp(sim(x_i, x^{'}_i))}{\exp(sim(x_i, x^{'}_i)) + \sum^K_{j = 1}\exp(sim(x_i, x^-_i))}
$$
问题：由于自然语言的离散特性，很难找到有效且无偏的数据增强策略来构建高质量的样本对。  

2. 人类反馈对比学习 (CLHF)  
人为利用标签信息构造正样本对，如利用自然语言推理数据集中具有蕴含关系的前提假设对作为正样本对，仍采用 InfoNCE 损失函数。 
问题：缺乏细粒度的监督信号。例如，在 InfoNCE 中，所有的正对都有一个标记为 1，但不同正样本对之间的相似度也存在差异。 

3. AI反馈对比学习 (CLAIF)
![](../imgs/屏幕截图%202024-05-11%20204743.jpg)
通过两步生成AI反馈的细粒度标签，采用 MSE 损失函数。

4. 人类和AI反馈对比学习 (CLHAIF)  
在人类和AI反馈都可用的情况下，将二者结合产生更好的监督信号。损失函数为 soft InfoNCE。

#### 1.2.2 CLAIF 与 CLHAIF 详细介绍
1. 生成文本对
使用不同的掩码率对 STS Benchmark 中未配对的句子进行掩码，然后利用 GPT-3 填补掩码以生成新的句子，最后将原始句子与生成的句子构造为文本对。
2. 语义相似度标注
使用 GPT-3 的 AI 反馈为每个句子对标注语义相似度分数。相似度得分范围从0到1，其中得分1表示两个句子的语义完全相同，得分0表示两个句子的语义完全不同。
3. 训练模型
利用生成的样本对，训练语言模型作为句子编码器，以获得更好的句子嵌入。由于给定具有细粒度相似度得分的句子对，不再需要显式地构造正负样本对，因此直接使用均方误差损失来拟合每个句子对与其 AI 反馈的余弦相似度。
$$
\mathcal{L}_{MSE} = \frac{1}{N}\sum^N_{i=1}[sim(x_i, x^{'}_i) - y_i]^2
$$
4. 结合人类与 AI 反馈
利用蕴含和矛盾关系构造正对 $(x_i, x^+_i)$ 和硬负对 $(x_i, x^-_i)$，并利用 GPT-3 的 AI 反馈为正对生成相似度分数 $y_i$。使用 soft InfoNCE loss:
$$
\mathcal{L}_{MSE} = -\frac{1}{N}\sum^N_{i=1}l_i
$$
$$
\mathcal{l_i} = y_i\log\frac{\exp(sim(x_i, x^+_i))/\tau}{\sum^N_{j = 1}(\exp(sim(x_i, x^+_j))/\tau + \exp(sim(x_i, x^-_j))/\tau)}
$$

## 二、后续相关工作
### 2.1 GISTEmbed Guided In-sample Selection of Training
在无监督对比学习中存在一些问题，如随机选择的负样本可能与查询正例相关，从而导致模型学习到不准确的嵌入表示。

本文提出了 GISTEmbed 框架来解决这些问题。该框架利用一个指导模型 (GB) 来动态选择样本中的负样本来进行对比学习。具体来说，在每个训练步骤中，模型接收到一批数据，包括查询、正例和负例。首先计算出这批数据中所有文本之间的相似度矩阵，并将它们传递给指导模型。如果指导模型认为某个负例子与查询正例相关，则将其从负样本集中移除。这样，只有那些与查询正例不相关的负例子才会被用于计算对比损失。这种方法不仅解决了随机选择负样本的问题，而且可以根据指导模型的判断动态调整负样本的数量和来源。

### 2.2 DenoSent A Denoising Objective for Self-Supervise
传统的基于对比学习的方法只关注了句子之间的关系，而忽略了句子内部的信息。本文提出的训练框架名为 DenoSent，旨在将自编码器应用于句子表示学习中，并结合对比学习来提高性能。该方法使用了 Transformer 作为基础模型，通过以下三个修改将其转化为一个句子表示学习模型：

1. 将编码器输出压缩为固定大小的向量。
2. 删除解码器中的多头注意力技术，仅保留单头注意力。
3. 在预测阶段，使用去噪策略而不是标准的自回归技术来预测原始句子。  

在训练过程中，DenoSent引入了两种类型的噪声：离散噪声和连续噪声。离散噪声是直接在词级别上引入的，包括删除、交换或打乱等简单操作。连续噪声则通过在嵌入句子上应用高比例的dropout来实现，以控制噪音水平。DenoSent 解决了句子表示学习中的一个重要问题，即如何在不依赖任何手动标签的情况下获得高质量的句子表示。通过利用自编码器和对比学习，该方法可以在无监督环境下训练出有效的句子表示，使模型能够同时获得句子内部和句子之间的监督信号。

### 2.3 Capturing the Relationship Between Sentence Triple
本文提出了一种新颖的损失目标函数，称为正负增强 (PNA)，可以应用于任何类型的句子三元组数据集，无论是由人类、LLM 还是由两者共同生成的。

PNA 损失目标函数是一种正则化方法，可以在训练过程中增加正样本和负样本的数量，从而提高模型的泛化能力。具体来说，PNA 损失函数通过将每个正样本与 k 个负样本组合成一个三元组来进行训练，其中 k 是一个超参数，可以根据实际情况进行调整。在训练过程中，PNA 损失函数会计算每个三元组的损失，并将其作为正样本的权重，以便更好地学习正样本和负样本之间的关系。
