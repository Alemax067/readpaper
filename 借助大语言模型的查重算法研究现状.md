# 借助大语言模型的查重算法研究现状
传统的查重算法主要依赖于文本的字面相似度，如词频、词向量等。然而，语言模型擅长语义理解，可以检测到表面上不同但语义相似的内容。这使得它们在处理复杂的文本改写、同义词替换等情况下具有更高的查重准确度。  

一些研究已经开始将语言模型应用于学术查重系统中。例如，使用 BERT 模型来捕捉学术论文中的语义相似度，帮助识别不同表达形式的相同学术观点。然而，想要在特定领域实现文本语义相似度的计算，依靠预训练的语义提取模型往往是不行的，需要大量高质量标注数据进行进一步的对比学习。这些数据如果依靠人力标注，将产生巨大的成本。因此，一些研究尝试利用大规模生成式语言模型来解决数据标注的难题。

## 一、Improving Contrastive Learning of Sentence Embeddings from AI Feedback

### 1.1 任务概述
通过对比学习增强文本嵌入的性能，提高文本嵌入的质量。

困境：文本对缺乏细粒度标注（如文本相似度的标签可以细分至 0.8、0.9，而非全部都是 0 或 1），无法进行有效的监督学习，而无监督学习又存在缺陷

### 1.2 方法概述

#### 1.2.1 对比学习方法总结
![](./imgs/屏幕截图%202024-08-31%20141526.jpg)

1. 零反馈对比学习 (CLZF)  
通过数据增强 (如 dropout ) 策略构造正样本对，不同句子组合作为负样本对。损失函数常用 InfoNCE:  
$$
\mathcal{L}_{InfoNCE} = -\log\frac{\exp(sim(x_i, x^{'}_i))}{\exp(sim(x_i, x^{'}_i)) + \sum^K_{j = 1}\exp(sim(x_i, x^-_i))}
$$
问题：由于自然语言的离散特性，很难找到有效且无偏的数据增强策略来构建高质量的样本对。  

2. 人类反馈对比学习 (CLHF)  
人为利用标签信息构造正样本对，如利用自然语言推理数据集中具有蕴含关系的前提假设对作为正样本对，仍采用 InfoNCE 损失函数。 
问题：缺乏细粒度的监督信号。例如，在 InfoNCE 中，所有的正对都有一个标记为 1，但不同正样本对之间的相似度也存在差异。 

3. AI反馈对比学习 (CLAIF)
![](./imgs/屏幕截图%202024-05-11%20204743.jpg)
通过两步生成AI反馈的细粒度标签，采用 MSE 损失函数。

4. 人类和AI反馈对比学习 (CLHAIF)  
在人类和AI反馈都可用的情况下，将二者结合产生更好的监督信号。损失函数为 soft InfoNCE。

#### 1.2.2 CLAIF 与 CLHAIF 详细介绍
1. 生成文本对
使用不同的掩码率对 STS Benchmark 中未配对的句子进行掩码，然后利用 GPT-3 填补掩码以生成新的句子，最后将原始句子与生成的句子构造为文本对。
2. 语义相似度标注
使用 GPT-3 的 AI 反馈为每个句子对标注语义相似度分数。相似度得分范围从0到1，其中得分1表示两个句子的语义完全相同，得分0表示两个句子的语义完全不同。
3. 训练模型
利用生成的样本对，训练语言模型作为句子编码器，以获得更好的句子嵌入。由于给定具有细粒度相似度得分的句子对，不再需要显式地构造正负样本对，因此直接使用均方误差损失来拟合每个句子对与其 AI 反馈的余弦相似度。
$$
\mathcal{L}_{MSE} = \frac{1}{N}\sum^N_{i=1}[sim(x_i, x^{'}_i) - y_i]^2
$$
4. 结合人类与 AI 反馈
利用蕴含和矛盾关系构造正对 $(x_i, x^+_i)$ 和硬负对 $(x_i, x^-_i)$，并利用 GPT-3 的 AI 反馈为正对生成相似度分数 $y_i$。使用 soft InfoNCE loss:
$$
\mathcal{L}_{MSE} = -\frac{1}{N}\sum^N_{i=1}l_i
$$
$$
\mathcal{l_i} = y_i\log\frac{\exp(sim(x_i, x^+_i))/\tau}{\sum^N_{j = 1}(\exp(sim(x_i, x^+_j))/\tau + \exp(sim(x_i, x^-_j))/\tau)}
$$

## 二、后续相关工作
